# -*- coding: utf-8 -*-
"""HealthData.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XMTDwSmN5PNJGGBc2nlPPko45xyOlNQI

https://chatgpt.com/share/68eb4da3-6cc4-8005-95b1-ac6cac3944b7
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv("health_dataset.csv")
df

"""Filtering symptoms for specific disease"""

disease_name = input("Enter disease name: ")


filtered = df[df["Disease Name"].str.lower() == disease_name.lower()]["Symptoms"]

print(filtered.to_string(index=False))

"""Find disease based on symptoms"""

input_symptoms = input("Enter symptoms (comma-separated): ").lower().split(",")


input_symptoms = [sym.strip() for sym in input_symptoms]


filtered = df[df["Symptoms"].str.lower().apply(lambda x: all(sym in x for sym in input_symptoms))]["Disease Name"]


print(filtered.to_string(index=False) if not filtered.empty else "No disease found with these symptoms.")

disease_name = input("Enter disease name: ")


doctor = df[df["Disease Name"].str.lower() == disease_name.lower()]["Doctor"]


print(doctor.to_string(index=False) if not doctor.empty else "Disease not found.")

""" code which will take user input of disease symptoms then based on the given disease it will show the disease name, type  of disease ,which doctor should i visit and what will be remedies:"""

symptom_input = input("Enter a symptom: ").strip().lower()

result = df[df["Symptoms"].str.lower().str.contains(symptom_input)]

if not result.empty:
    print(f"\nDiseases found with the symptom '{symptom_input}':")

    print(result.to_string(index=False))
else:
    print("Sorry, no disease found with this symptom.")

"""# Task
Apply machine learning models and algorithms to the data in "/content/health_dataset.csv" for disease prediction.
"""

df = pd.read_csv("health_dataset.csv")
display(df.head())
df.info()
display(df.describe())

"""## Preprocess the data

### Subtask:
Clean the data, handle missing values, and prepare it for machine learning models. This might involve text preprocessing for the 'Symptoms' column and encoding categorical features.

**Reasoning**:
Convert 'Symptoms' to lowercase, strip whitespace from each symptom, split into a list, and convert specified columns to category data type for data cleaning and preparation for machine learning.
"""

df['Symptoms'] = df['Symptoms'].str.lower().str.split(',').apply(lambda x: [symptom.strip() for symptom in x])
df['Type of Disease'] = df['Type of Disease'].astype('category')
df['Doctor'] = df['Doctor'].astype('category')
df['Remedies'] = df['Remedies'].astype('category')
display(df.head())

"""## Feature engineering

### Subtask:
Create new features from the existing ones that might help improve the model's performance.

**Reasoning**:
Convert the list of symptoms back into a single string, then use TfidfVectorizer to create numerical features.
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

df['Symptoms_str'] = df['Symptoms'].apply(lambda x: ' '.join(x))
vectorizer = TfidfVectorizer()
X_vec = vectorizer.fit_transform(df['Symptoms_str'])

"""## Split the data

### Subtask:
Split the data into training and testing sets.

**Reasoning**:
Split the data into training and testing sets using train_test_split.
"""

from sklearn.model_selection import train_test_split

X = X_vec
y = df["Disease Name"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

"""## Choose and train a model

### Subtask:
Select an appropriate machine learning model for classification (since you are predicting disease names) and train it on the training data. Given the small dataset, we might consider models that are less prone to overfitting or explore techniques like cross-validation.

**Reasoning**:
Instantiate and train a Multinomial Naive Bayes model on the training data.
"""

model = MultinomialNB()
model.fit(X_train, y_train)

"""## Evaluate the model

### Subtask:
Evaluate the trained model's performance using appropriate metrics (e.g., accuracy, precision, recall, F1-score).

**Reasoning**:
Evaluate the trained model's performance using accuracy and classification report.
"""

y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""## Improve the model

### Subtask:
Based on the evaluation results, try to improve the model by tuning hyperparameters, trying different models, or using techniques like ensemble methods.

**Reasoning**:
Based on the poor performance of the Multinomial Naive Bayes model, I will now train and evaluate a Support Vector Machine (SVM) model, which is another suitable algorithm for text classification and can sometimes perform better than Naive Bayes on smaller datasets. I will use default parameters initially.
"""

from sklearn.svm import SVC

# Choose and train a Support Vector Machine model
svm_model = SVC()
svm_model.fit(X_train, y_train)

# Evaluate the SVM model
y_pred_svm = svm_model.predict(X_test)
print("SVM Accuracy:", accuracy_score(y_test, y_pred_svm))
print("SVM Classification Report:")
print(classification_report(y_test, y_pred_svm))

"""**Reasoning**:
The SVM model showed a slight improvement in accuracy compared to the Naive Bayes model, but the overall performance is still poor, likely due to the small dataset and class imbalance. To further explore potential improvements, I will now try a Logistic Regression model, which is another linear model that can be effective for text classification and is less sensitive to the assumptions of Naive Bayes. I will also use default parameters initially.


"""

from sklearn.linear_model import LogisticRegression

# Choose and train a Logistic Regression model
lr_model = LogisticRegression(max_iter=1000) # Increased max_iter for convergence
lr_model.fit(X_train, y_train)

# Evaluate the Logistic Regression model
y_pred_lr = lr_model.predict(X_test)
print("\nLogistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print("Logistic Regression Classification Report:")
print(classification_report(y_test, y_pred_lr))

"""**Reasoning**:
Both Logistic Regression and Naive Bayes models performed poorly, while SVM showed a slight improvement. Given the small dataset and class imbalance, it's challenging to achieve high accuracy with simple models. Hyperparameter tuning might not significantly improve performance on such a small dataset. Ensemble methods could potentially help, but the base models are already struggling. Another option is to use a model that is generally robust to small datasets and imbalanced classes, such as a tree-based model. I will try a Random Forest classifier next.


"""

from sklearn.ensemble import RandomForestClassifier

# Choose and train a Random Forest model
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# Evaluate the Random Forest model
y_pred_rf = rf_model.predict(X_test)
print("\nRandom Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Random Forest Classification Report:")
print(classification_report(y_test, y_pred_rf))

"""## Summary:

### Data Analysis Key Findings

*   The dataset contains 100 rows and 5 columns: 'Disease Name', 'Type of Disease', 'Symptoms', 'Doctor', and 'Remedies'.
*   Initially, all columns were of object data type and had no missing values.
*   The 'Symptoms' column was successfully preprocessed by converting to lowercase, splitting by commas, and removing leading/trailing whitespace, resulting in a list of symptoms for each entry.
*   'Type of Disease', 'Doctor', and 'Remedies' columns were converted to the 'category' data type.
*   Feature engineering was performed on the 'Symptoms' column by joining the list of symptoms into a single string ('Symptoms\_str') and applying TF-IDF vectorization to create a numerical feature representation (`X_vec`).
*   The data was split into training and testing sets with a test size of 20%, resulting in `X_train` (80 samples, 129 features), `X_test` (20 samples, 129 features), `y_train` (80 samples), and `y_test` (20 samples).
*   An initial Multinomial Naive Bayes model achieved an accuracy of 0.1 on the test set, with very low precision, recall, and F1-scores for most classes.
*   Attempting to improve the model by trying other classifiers (SVM, Logistic Regression, and Random Forest) did not yield better results, with accuracies of 0.15, 0.10, and 0.05 respectively. All models showed poor performance across most disease classes, likely due to the small dataset size and potential class imbalance.

### Insights or Next Steps

*   The current dataset is likely too small and potentially imbalanced for effective disease prediction using the explored models and feature engineering techniques.
*   To improve model performance, acquiring a larger and more balanced dataset with more diverse symptoms and disease instances would be crucial.

https://chatgpt.com/share/68ef7d9d-01ec-8005-ab95-376275623353
"""



import joblib

# Save the Random Forest model
filename = 'rf_model.sav'
joblib.dump(rf_model, filename)

print(f"Random Forest model saved as {filename}")

"""You can then download the saved file (`rf_model.sav`) from your Colab environment.

Please remember that this model's performance is very poor due to the small dataset it was trained on.

Random Forest like a team of doctors trying to diagnose a patient. Each doctor is like a "decision tree" in the forest.

- n_estimators (Number of doctors): This is how many doctors are on the team. More doctors might give a better overall opinion, but it takes more time for all of them to examine the patient.

- max_depth (How deep each doctor thinks): This limits how many questions each doctor can ask or how many tests they can order. If they can go too deep, they might get too focused on tiny details and miss the bigger picture (overfitting).

- min_samples_split (Minimum patients to discuss a symptom): Imagine doctors only discuss a symptom if a certain number of patients have it. This prevents them from making decisions based on just one or two unusual cases.

- min_samples_leaf (Minimum patients with a final diagnosis): This is like saying a doctor can only make a final diagnosis if a certain number of patients with similar symptoms end up in that diagnosis group.

- max_features (Number of symptoms each doctor looks at): When diagnosing, each doctor might only focus on a random subset of the patient's symptoms, not all of them. This helps the team get different perspectives.

- random_state (Having a consistent process): This is like making sure the team of doctors follows the same general process each time, so you get similar results if you run the diagnosis again with the same patient information.

So, the hyperparameters are just settings that control how this "team of doctors" (the Random Forest) works together to make a diagnosis (prediction). By adjusting these settings, you can try to make the team more accurate or faster.
"""



"""# Task
Build an API using Flask to serve a machine learning model.

## Install flask

### Subtask:
Install the Flask library in your Colab environment.

**Reasoning**:
The subtask is to install the Flask library. I will use pip to install the library in a separate code cell.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install Flask

"""## Create a flask app

### Subtask:
Write the basic code to initialize a Flask application.

**Reasoning**:
Initialize a Flask application by importing the Flask class and creating an instance.
"""

from flask import Flask

app = Flask(__name__)

"""## Define api endpoints

### Subtask:
Create routes for your API that will handle incoming requests (e.g., a route to receive symptom data).

**Reasoning**:
Define a route to handle incoming requests for prediction and add a placeholder for processing the request.
"""

@app.route('/predict', methods=['POST'])
def predict():
    # Placeholder for receiving symptom data and making predictions
    return "Prediction endpoint"

"""## Integrate the model

### Subtask:
Load the trained model and use it within an API endpoint to make predictions based on the received data.

**Reasoning**:
Load the trained Random Forest model and use it within the Flask API's /predict endpoint to receive symptom data, preprocess it using the existing vectorizer, make a prediction, and return the predicted disease name as a JSON response.
"""

import joblib
from flask import request, jsonify

# Load the trained model
model = joblib.load('rf_model.sav')

# Remove the existing route definition for /predict if it exists
if 'predict' in app.view_functions:
    del app.view_functions['predict']

@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json(force=True)
    symptoms = data['symptoms']

    # Preprocess the symptom data
    symptoms_list = [s.strip().lower() for s in symptoms.split(',')]
    symptoms_str = ' '.join(symptoms_list)

    # Transform the preprocessed symptom string using the fitted vectorizer
    X_new = vectorizer.transform([symptoms_str])

    # Make a prediction
    prediction = model.predict(X_new)

    # Return the prediction as a JSON response
    return jsonify({'predicted_disease': prediction[0]})

"""## Run the flask app

### Subtask:
Add code to run the Flask development server.

**Reasoning**:
Import the `run_simple` function from `werkzeug.serving` and run the Flask application.
"""

from werkzeug.serving import run_simple

if __name__ == '__main__':
    run_simple('0.0.0.0', 5000, app, threaded=True)

"""## Test the API

### Subtask:
Provide instructions or code examples on how to test the API endpoints.

**Reasoning**:
Use the `requests` library to send a POST request to the `/predict` endpoint with sample symptom data and print the JSON response to test the API.
"""

import requests
import json

# Replace with the actual URL of your Flask app if running locally or deployed
# If running in Colab, you'll need to use a service like ngrok to expose your local server
# For testing within Colab, you can send requests to the local address
url = 'http://127.0.0.1:5000/predict'  # Or the Colab internal IP if accessible

# Sample symptom data
data = {'symptoms': 'fever, cough, fatigue'}

# Send POST request
response = requests.post(url, json=data)

# Print the response
print("Status Code:", response.status_code)
print("Response Body:", response.json())

